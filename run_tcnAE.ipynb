{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tcnAutoencoder import TCNAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 738034 unique order book shapshots from ./data/hft_data/AAPL/AAPL_2024-03-01_34200000_57600000_message_10.csv\n",
      "Read 1923409 unique order book shapshots from ./data/hft_data/AAPL/AAPL_2024-03-04_34200000_57600000_message_10.csv\n",
      "Read 2108353 unique order book shapshots from ./data/hft_data/AAPL/AAPL_2024-03-05_34200000_57600000_message_10.csv\n",
      "Read 2364167 unique order book shapshots from ./data/hft_data/AAPL/AAPL_2024-03-06_34200000_57600000_message_10.csv\n",
      "Read 1732063 unique order book shapshots from ./data/hft_data/AAPL/AAPL_2024-03-07_34200000_57600000_message_10.csv\n",
      "Read 3123866 unique order book shapshots from ./data/hft_data/AAPL/AAPL_2024-03-08_34200000_57600000_message_10.csv\n"
     ]
    }
   ],
   "source": [
    "# %load load_data.py\n",
    "import pandas as pd\n",
    "import glob, os, re\n",
    "\n",
    "\n",
    "# Read the data only once.  It's big!\n",
    "csv_files = glob.glob(os.path.join(\".\", \"data\", \"hft_data\", \"*\", \"*_message_*.csv\"))\n",
    "date_str = re.compile(r'_(\\d{4}-\\d{2}-\\d{2})_')\n",
    "stock_str = re.compile(r'([A-Z]+)_\\d{4}-\\d{2}-\\d{2}_')\n",
    "\n",
    "df_list = []\n",
    "day_list = []\n",
    "sym_list = []\n",
    "\n",
    "for csv_file in sorted(csv_files):\n",
    "    date = date_str.search(csv_file)\n",
    "    date = date.group(1)\n",
    "    day_list.append(date)\n",
    "\n",
    "    symbol = stock_str.search(csv_file)\n",
    "    symbol = symbol.group(1)\n",
    "    sym_list.append(symbol)\n",
    "\n",
    "    # Find the order book file that matches this message file.\n",
    "    book_file = csv_file.replace(\"message\", \"orderbook\")\n",
    "\n",
    "    # Read the message file and index by timestamp.\n",
    "    df = pd.read_csv(csv_file, names=['Time','EventType','OrderID','Size','Price','Direction'])\n",
    "    df['Time'] = pd.to_datetime(date) + pd.to_timedelta(df['Time'], unit='s')\n",
    "\n",
    "    # Read the order book file and merge it with the messages.\n",
    "    names = [f\"{x}{i}\" for i in range(1,11) for x in [\"AP\",\"AS\",\"BP\",\"BS\"]]\n",
    "    df = df.join(pd.read_csv(book_file, names=names), how='inner')\n",
    "    df = df.set_index(['Time'])\n",
    "\n",
    "    BBID_COL = df.columns.get_loc(\"BP1\")\n",
    "    BASK_COL = df.columns.get_loc(\"AP1\")\n",
    "\n",
    "    print (f\"Read {df.shape[0]} unique order book shapshots from {csv_file}\")\n",
    "\n",
    "    df_list.append(df)\n",
    "\n",
    "days = len(day_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:  (234000, 2)\n",
      "original shape:  (234000, 2)\n",
      "original shape:  (234000, 2)\n",
      "original shape:  (234000, 2)\n",
      "original shape:  (234000, 2)\n",
      "original shape:  (234000, 2)\n"
     ]
    }
   ],
   "source": [
    "def prep_data(df) -> pd.DataFrame:\n",
    "    df = df[['Price', 'Size']]\n",
    "    df.head()\n",
    "\n",
    "    # sample every 100ms, and the size would be the sum of the size in that 100ms. \n",
    "    # Price would be the average price in that 100ms.\n",
    "    df = df.resample('100ms').agg({'Price': 'mean', 'Size': 'sum'})\n",
    "\n",
    "    # Check for NaN values\n",
    "\n",
    "    # forwardfill all NaN values in the data\n",
    "    df = df.ffill()\n",
    "\n",
    "    # normalize the data with mean and std\n",
    "    mean = df['Price'].mean()\n",
    "    std = df['Price'].std()\n",
    "    df['Price'] = (df['Price'] - mean) / std\n",
    "\n",
    "    mean = df['Size'].mean()\n",
    "    std = df['Size'].std()\n",
    "    df['Size'] = (df['Size'] - mean) / std\n",
    "\n",
    "    print(\"original shape: \", df.shape)\n",
    "\n",
    "    df = df.values\n",
    "    # Create a tensor for every 30 minutes of data\n",
    "    tensors = []\n",
    "    for i in range(0, len(df), 18000):\n",
    "        if i + 18000 < len(df):\n",
    "            # flip the first and second dimension, so that the shape is (batch_size, channel, sequence_length)\n",
    "            tensors.append(torch.tensor(df[i:i+18000]).unsqueeze(0))\n",
    "        else:\n",
    "            tensors.append(torch.tensor(df[i:]).unsqueeze(0))\n",
    "\n",
    "    return tensors\n",
    "\n",
    "    # Create the final torch tensor, every 1 hour is a sequence\n",
    "\n",
    "tensors_list = []\n",
    "for df in df_list: \n",
    "    tensors_list.extend(prep_data(df_list[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n",
      "torch.Size([1, 18000, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filp the first and second dimension, so that the shape is (batch_size, channel, sequence_length)\n",
    "tensors_list = [tensor.permute(0, 2, 1) for tensor in tensors_list]\n",
    "\n",
    "[print(tensor.shape) for tensor in tensors_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chan/.pyenv/versions/3.11.8/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([62, 2, 18000])) that is different to the input size (torch.Size([62, 2, 17990])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (17990) must match the size of tensor b (18000) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/site-packages/torch/nn/modules/loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/site-packages/torch/nn/functional.py:3338\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3336\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3338\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/site-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (17990) must match the size of tensor b (18000) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Start the training process with tensors.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TCNAutoencoder(input_dim=(2, 18000)).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# Randomly sample 0.2 of the data from the batch for testing, excluding them for traning.\n",
    "tensors = tensors_list\n",
    "tensors_train = tensors[:int(len(tensors) * 0.8)]\n",
    "tensors_test = tensors[int(len(tensors) * 0.8):]\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    # pack the data into one tensor\n",
    "    data = torch.cat(tensors_train, dim=0).to(device).float()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
